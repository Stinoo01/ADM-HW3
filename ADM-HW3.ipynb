{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MY IDEA --> I have to create a function that retrieve the required information from a html page. ion order to do so I exploit the structure of the file. \n",
    "#I use \"try: except:\" to avoid errors in the case that some information is missing\n",
    "\n",
    "def extract_msc_page(msc_page_url):\n",
    "\n",
    "\n",
    "    contents ={}\n",
    "    # Parse HTML content\n",
    "    page_soup = BeautifulSoup(msc_page_url, 'html.parser')\n",
    "\n",
    "    #url\n",
    "    try:\n",
    "        canonical_link = page_soup.find('link', {'rel': 'canonical'})\n",
    "        contents['url'] = canonical_link.get('href')\n",
    "    except AttributeError:\n",
    "        contents['url'] = \"\"\n",
    "\n",
    "\n",
    "    # Course name\n",
    "    try:\n",
    "        page_links = page_soup.find('h1', {'class': 'text-white course-header__course-title'})\n",
    "        name = page_links.get_text()\n",
    "        contents[\"courseName\"] = name.strip()\n",
    "    except AttributeError:\n",
    "        contents['courseName'] = \"\"\n",
    "\n",
    "    # University name\n",
    "    try:\n",
    "        page_links = page_soup.find_all('a', {'class': 'course-header__institution'})\n",
    "        contents['universityName'] = page_links[0].contents[0].strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        contents['universityName'] = \"\"\n",
    "\n",
    "    # Faculty name\n",
    "    try:\n",
    "        page_links = page_soup.find_all('a', {'class': 'course-header__department'})\n",
    "        contents['facultyName'] = page_links[0].contents[0].strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        contents['facultyName'] = \"\"\n",
    "\n",
    "    # Full time\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'inheritFont concealLink text-decoration-none text-gray-600'})\n",
    "        time = page_links.get_text().strip()\n",
    "        contents['isItFullTime'] = time\n",
    "    except AttributeError:\n",
    "        contents['isItFullTime'] = \"\"\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        page_links = page_soup.find('div', {'id': 'Snippet'})\n",
    "        description = page_links.get_text().strip()\n",
    "        contents[\"description\"] = description\n",
    "    except AttributeError:\n",
    "        contents['description'] = \"\"\n",
    "\n",
    "    # Starting date\n",
    "    try:\n",
    "        page_links = page_soup.find('span', {'class': 'key-info__content key-info__start-date py-2 pr-md-3 text-nowrap d-block d-md-inline-block'})\n",
    "        starting = page_links.get_text().strip()\n",
    "        contents[\"startDate\"] = starting\n",
    "    except AttributeError:\n",
    "        contents['startDate'] = \"\"\n",
    "\n",
    "    # Fees\n",
    "    try:\n",
    "        page_links = page_soup.find('div', {'class': 'course-sections course-sections__fees tight col-xs-24'})\n",
    "        fees = page_links.get_text().strip()\n",
    "        contents[\"fees\"] = fees\n",
    "    except AttributeError:\n",
    "        contents['fees'] = \"\"\n",
    "\n",
    "    # Modality\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'title': 'View all MSc courses'})\n",
    "        modality = page_links.get_text().strip()\n",
    "        contents[\"modality\"] = modality\n",
    "    except AttributeError:\n",
    "        contents['modality'] = \"\"\n",
    "\n",
    "    # Duration\n",
    "    try:\n",
    "        page_links = page_soup.find('span', {'class': 'key-info__content key-info__duration py-2 pr-md-3 d-block d-md-inline-block'})\n",
    "        duration = page_links.get_text().strip()\n",
    "        contents[\"duration\"] = duration\n",
    "    except AttributeError:\n",
    "        contents['duration'] = \"\"\n",
    "\n",
    "    # City\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__city'})\n",
    "        city = page_links.get_text().strip()\n",
    "        contents[\"city\"] = city\n",
    "    except AttributeError:\n",
    "        contents['city'] = \"\"\n",
    "\n",
    "    # Country\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__country'})\n",
    "        country = page_links.get_text().strip()\n",
    "        contents[\"country\"] = country\n",
    "    except AttributeError:\n",
    "        contents['country'] = \"\"\n",
    "\n",
    "    # Administration\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__on-campus'})\n",
    "        administration = page_links.get_text().strip()\n",
    "        contents[\"administration\"] = administration\n",
    "    except AttributeError:\n",
    "        contents[\"administration\"] = \"\"\n",
    "\n",
    "    \n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_25888\\832032047.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(result_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_pages/page_99\\bioinnovation-msc.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_25888\\832032047.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(result_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_pages/page_99\\biological-photography-and-imaging-msc.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_25888\\832032047.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(result_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_pages/page_99\\biological-sciences-m-a-m-s.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_25888\\832032047.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(result_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_pages/page_99\\biological-sciences-msc-by-research.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_25888\\832032047.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(result_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "## MY IDEA --> I apply the function above for all the files. I am applying it for all files in a folder for all folders contained into a folder\n",
    "\n",
    "folder_path = 'html_pages/'\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "# Walk through the directory and its subdirectories\n",
    "for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "    # Iterate through all the files in the current subdirectory\n",
    "    for filename in filenames:\n",
    "        # Construct the file path\n",
    "        path = os.path.join(foldername, filename)\n",
    "        \n",
    "        # Check if the file exists before attempting to open it\n",
    "        if os.path.exists(path):\n",
    "            # Print the file path\n",
    "            print(path)\n",
    "            \n",
    "            # Open the file in read mode with UTF-8 encoding\n",
    "            with open(path, 'r', encoding='utf-8') as file:\n",
    "                # Read the HTML content of the file\n",
    "                html_content = file.read()\n",
    "                \n",
    "                # Call the function to extract information from the HTML content\n",
    "                result_dict = extract_msc_page(html_content)\n",
    "                result_df = result_df.append(result_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Print a message if the file is not found\n",
    "            print(f\"File not found: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean an imperfection in the fees section\n",
    "result_df['fees'] = result_df['fees'].str.replace('Fees', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it into a file to store it. so that I do not have to run it again\n",
    "result_df.to_json('html_pages.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_json(\"html_pages.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'tsv_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stefa\\OneDrive\\Desktop\\ADM-HW3.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefa/OneDrive/Desktop/ADM-HW3.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     selected_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcourseName\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muniversityName\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfacultyName\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39misItFullTime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstartDate\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefa/OneDrive/Desktop/ADM-HW3.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mfees\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodality\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcity\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39madministration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefa/OneDrive/Desktop/ADM-HW3.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     selected_data \u001b[39m=\u001b[39m row[selected_columns]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefa/OneDrive/Desktop/ADM-HW3.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     selected_data\u001b[39m.\u001b[39mto_csv(file_path, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefa/OneDrive/Desktop/ADM-HW3.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTSV files created successfully.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'tsv_files'"
     ]
    }
   ],
   "source": [
    "#create the tsv files \n",
    "output_directory = \"tsv_files/\"\n",
    "\n",
    "\n",
    "# Iterate through each row and create a TSV file\n",
    "for index, row in result_df.iterrows():\n",
    "    file_name = f\"course_{index}.tsv\"\n",
    "    file_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "    # Extract relevant columns and write to the TSV file\n",
    "    selected_columns = ['courseName', 'universityName', 'facultyName', 'isItFullTime', 'description', 'startDate',\n",
    "                        'fees','modality','duration','city','country','administration', 'url']\n",
    "    selected_data = row[selected_columns]\n",
    "    selected_data.to_csv(file_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"TSV files created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
