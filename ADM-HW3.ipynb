{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Get the list of master's degree courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False # run only once\n",
    "\n",
    "if flag:\n",
    "    # URL of the website\n",
    "    url = 'https://www.findamasters.com/masters-degrees/msc-degrees/?PG='  \n",
    "    prefix = '/masters-degrees/course/'\n",
    "    exclude = ['\\nMore details \\n', '\\nRead more \\n', '\\xa0Video(s)', '\\xa0Student Profile(s)'] \n",
    "\n",
    "    # Create a list to store the URLs of the masters\n",
    "    master_urls = []\n",
    "\n",
    "    # Loop through the first 400 pages\n",
    "    for page_number in range(1, 401):\n",
    "        print(url + str(page_number))\n",
    "        response = requests.get(url + str(page_number))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "            # Use BeautifulSoup to extract the URLs and append them to the master_urls list\n",
    "            for link in soup.find_all('a', {'class':'courseLink'}):\n",
    "                if link['href'][:len(prefix)] == prefix and not link.text in exclude:\n",
    "                    master_urls.append((link['href'], link.text))\n",
    "\n",
    "\n",
    "    # Save the collected URLs in a text file\n",
    "    with open(\"master_urls.txt\", \"a\") as file:\n",
    "        for url in master_urls:\n",
    "            file.write(url[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Crawl master's degree pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "\n",
    "if flag:\n",
    "    # Open the file and read its content\n",
    "    with open(\"master_urls.txt\", \"r\") as file:\n",
    "        master_urls = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    # Create a directory to store HTML pages\n",
    "    output_root_directory = \"html_pages\"\n",
    "    os.makedirs(output_root_directory, exist_ok=True)  # create the directory if it doen't exist\n",
    "\n",
    "    # Read 15 URLs at a time and create HTML pages\n",
    "    subset_size = 15\n",
    "    for i in range(0, len(master_urls), subset_size):\n",
    "        subset = master_urls[i:i + subset_size] # extract 15 more urls\n",
    "\n",
    "        # Create a subfolder for each page\n",
    "        output_directory = os.path.join(output_root_directory, f\"page_{i // subset_size + 1}\")\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        # Create an HTML page for each URL in the subset\n",
    "        for url in subset:\n",
    "            prefix = 'https://www.findamasters.com/'\n",
    "            response = requests.get(prefix + url)  # sends a GET request \n",
    "\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                page_content = soup.prettify()  # extract the content of the page          \n",
    "                master_name = url.split(\"/\")[-2]  # extract the name of the master from the URL \n",
    "\n",
    "                # Check if the file already exists, and append a number if necessary\n",
    "                page_filename = f\"{output_directory}/{master_name}.html\"\n",
    "                counter = 1\n",
    "                while os.path.exists(page_filename):\n",
    "                    page_filename = f\"{output_directory}/{master_name}({counter}).html\"\n",
    "                    counter += 1\n",
    "\n",
    "                # Save the content in a HTML file\n",
    "                with open(page_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(page_content)\n",
    "            time.sleep(1.5)\n",
    "\n",
    "        print(f\"page {i // subset_size + 1} completed\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MY IDEA --> I have to create a function that retrieve the required information from a html page. in order to do so I exploit the structure of the file. \n",
    "#I use \"try: except:\" to avoid errors in the case that some information is missing\n",
    "\n",
    "def extract_msc_page(msc_page_url):\n",
    "\n",
    "\n",
    "    contents ={}\n",
    "    # Parse HTML content\n",
    "    page_soup = BeautifulSoup(msc_page_url, 'html.parser')\n",
    "\n",
    "    #url\n",
    "    try:\n",
    "        canonical_link = page_soup.find('link', {'rel': 'canonical'})\n",
    "        contents['url'] = canonical_link.get('href')\n",
    "    except AttributeError:\n",
    "        contents['url'] = \"\"\n",
    "\n",
    "\n",
    "    # Course name\n",
    "    try:\n",
    "        page_links = page_soup.find('h1', {'class': 'text-white course-header__course-title'})\n",
    "        name = page_links.get_text()\n",
    "        contents[\"courseName\"] = name.strip()\n",
    "    except AttributeError:\n",
    "        contents['courseName'] = \"\"\n",
    "\n",
    "    # University name\n",
    "    try:\n",
    "        page_links = page_soup.find_all('a', {'class': 'course-header__institution'})\n",
    "        contents['universityName'] = page_links[0].contents[0].strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        contents['universityName'] = \"\"\n",
    "\n",
    "    # Faculty name\n",
    "    try:\n",
    "        page_links = page_soup.find_all('a', {'class': 'course-header__department'})\n",
    "        contents['facultyName'] = page_links[0].contents[0].strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        contents['facultyName'] = \"\"\n",
    "\n",
    "    # Full time\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'inheritFont concealLink text-decoration-none text-gray-600'})\n",
    "        time = page_links.get_text().strip()\n",
    "        contents['isItFullTime'] = time\n",
    "    except AttributeError:\n",
    "        contents['isItFullTime'] = \"\"\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        page_links = page_soup.find('div', {'id': 'Snippet'})\n",
    "        description = page_links.get_text().strip()\n",
    "        contents[\"description\"] = description\n",
    "    except AttributeError:\n",
    "        contents['description'] = \"\"\n",
    "\n",
    "    # Starting date\n",
    "    try:\n",
    "        page_links = page_soup.find('span', {'class': 'key-info__content key-info__start-date py-2 pr-md-3 text-nowrap d-block d-md-inline-block'})\n",
    "        starting = page_links.get_text().strip()\n",
    "        contents[\"startDate\"] = starting\n",
    "    except AttributeError:\n",
    "        contents['startDate'] = \"\"\n",
    "\n",
    "    # Fees\n",
    "    try:\n",
    "        page_links = page_soup.find('div', {'class': 'course-sections course-sections__fees tight col-xs-24'})\n",
    "        fees = page_links.get_text().strip()\n",
    "        contents[\"fees\"] = fees\n",
    "    except AttributeError:\n",
    "        contents['fees'] = \"\"\n",
    "\n",
    "    # Modality\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'title': 'View all MSc courses'})\n",
    "        modality = page_links.get_text().strip()\n",
    "        contents[\"modality\"] = modality\n",
    "    except AttributeError:\n",
    "        contents['modality'] = \"\"\n",
    "\n",
    "    # Duration\n",
    "    try:\n",
    "        page_links = page_soup.find('span', {'class': 'key-info__content key-info__duration py-2 pr-md-3 d-block d-md-inline-block'})\n",
    "        duration = page_links.get_text().strip()\n",
    "        contents[\"duration\"] = duration\n",
    "    except AttributeError:\n",
    "        contents['duration'] = \"\"\n",
    "\n",
    "    # City\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__city'})\n",
    "        city = page_links.get_text().strip()\n",
    "        contents[\"city\"] = city\n",
    "    except AttributeError:\n",
    "        contents['city'] = \"\"\n",
    "\n",
    "    # Country\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__country'})\n",
    "        country = page_links.get_text().strip()\n",
    "        contents[\"country\"] = country\n",
    "    except AttributeError:\n",
    "        contents['country'] = \"\"\n",
    "\n",
    "    # Administration\n",
    "    try:\n",
    "        page_links = page_soup.find('a', {'class': 'card-badge text-wrap text-left badge badge-gray-200 p-2 m-1 font-weight-light course-data course-data__on-campus'})\n",
    "        administration = page_links.get_text().strip()\n",
    "        contents[\"administration\"] = administration\n",
    "    except AttributeError:\n",
    "        contents[\"administration\"] = \"\"\n",
    "\n",
    "    \n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MY IDEA --> I apply the function above for all the files. I am applying it for all files in a folder for all folders contained into a folder\n",
    "\n",
    "flag = False\n",
    "\n",
    "if flag:\n",
    "    folder_path = 'html_pages/'\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "        # Iterate through all the files in the current subdirectory\n",
    "        for filename in filenames:\n",
    "            # Construct the file path\n",
    "            path = os.path.join(foldername, filename)\n",
    "        \n",
    "            # Check if the file exists before attempting to open it\n",
    "            if os.path.exists(path):\n",
    "                # Print the file path\n",
    "                print(path)\n",
    "            \n",
    "                # Open the file in read mode with UTF-8 encoding\n",
    "                with open(path, 'r', encoding='utf-8') as file:\n",
    "                    # Read the HTML content of the file\n",
    "                    html_content = file.read()\n",
    "                \n",
    "                    # Call the function to extract information from the HTML content\n",
    "                    result_dict = extract_msc_page(html_content)\n",
    "                    result_df = result_df.append(result_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "            else:\n",
    "                # Print a message if the file is not found\n",
    "                print(f\"File not found: {path}\")\n",
    "\n",
    "\n",
    "    #clean an imperfection in the fees section\n",
    "    result_df['fees'] = result_df['fees'].str.replace('Fees', '') \n",
    "\n",
    "    #save it into a file to store it. so that I do not have to run it again\n",
    "    result_df.to_json('html_pages.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV files created successfully.\n"
     ]
    }
   ],
   "source": [
    "#create the tsv files \n",
    "\n",
    "data = pd.read_json(\"html_pages.json\", lines=True)\n",
    "\n",
    "output_directory = \"tsv_files/\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through each row and create a TSV file\n",
    "for index, row in data.iterrows():\n",
    "    file_name = f\"course_{index}.tsv\"\n",
    "    file_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "    # Extract relevant columns and write to the TSV file\n",
    "    selected_columns = ['courseName', 'universityName', 'facultyName', 'isItFullTime', 'description', 'startDate',\n",
    "                        'fees','modality','duration','city','country','administration', 'url']\n",
    "    selected_data = row[selected_columns]\n",
    "    selected_data.to_csv(file_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"TSV files created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.0) Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords # import stopwords module\n",
    "\n",
    "\n",
    "dataset = pd.read_json(\"html_pages.json\", lines=True)  # read the dataset from the created json file\n",
    "dataset = dataset[dataset.description != '']  # filter rows where the 'description' is empty\n",
    "\n",
    "# STEMMING\n",
    "stemmer = PorterStemmer()  # create an instance of Porter Stemmer\n",
    "dataset['preprocessed_description'] = dataset.description.apply(lambda row: [stemmer.stem(word) for word in row.split(' ')])  # reduce words of description column to their root form and create a new column to store the result\n",
    "\n",
    "# STOPWORDS\n",
    "nltk.download('stopwords') \n",
    "list_stopwords = stopwords.words('english')  # retrieves the English stopwords from the nltk stopwords dataset\n",
    "dataset['preprocessed_description'] = dataset.description.apply(lambda row: [stemmer.stem(word) for word in row.split(' ') if not word in list_stopwords])  # now 'descr_clean' column contains lists of cleaned and stemmed words \n",
    "\n",
    "# PUNCTUATION\n",
    "nltk.download('punkt')\n",
    "dataset['preprocessed_description'] = dataset.description.apply(lambda row: [stemmer.stem(word) for word in nltk.word_tokenize(row) if not word in list_stopwords and word.isalnum()]) # now 'descr_clean' column contains lists of cleaned and stemmed words without punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>preprocessed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>3D Design for Virtual Environments - MSc</td>\n",
       "      <td>Glasgow Caledonian University</td>\n",
       "      <td>School of Engineering and Built Environment</td>\n",
       "      <td>Full time</td>\n",
       "      <td>3D visualisation and animation play a role in ...</td>\n",
       "      <td>September</td>\n",
       "      <td>\\n          \\n\\n\\n\\n             Please see th...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>[3d, visualis, anim, play, role, mani, area, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>King’s Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>September</td>\n",
       "      <td>\\n          \\n\\n\\n\\n             Please see th...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>[our, account, account, financi, manag, msc, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>Accounting and Finance - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Leeds University Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>September</td>\n",
       "      <td>\\n          \\n\\n\\n            UK: £18,000 (Tot...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>[busi, govern, reli, sound, financi, knowledg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>Accounting, Financial Management and Digital B...</td>\n",
       "      <td>University of Reading</td>\n",
       "      <td>Henley Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Embark on a professional accounting career wit...</td>\n",
       "      <td>September</td>\n",
       "      <td>\\n          \\n\\n\\n\\n             Please see th...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Reading</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>[embark, profession, account, career, academ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>Addictions MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Institute of Psychiatry, Psychology and Neuros...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join us for an online session for prospective ...</td>\n",
       "      <td>September</td>\n",
       "      <td>\\n          \\n\\n\\n\\n             Please see th...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>One year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>[join, us, onlin, session, prospect, student, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.findamasters.com/masters-degrees/c...   \n",
       "1  https://www.findamasters.com/masters-degrees/c...   \n",
       "2  https://www.findamasters.com/masters-degrees/c...   \n",
       "3  https://www.findamasters.com/masters-degrees/c...   \n",
       "4  https://www.findamasters.com/masters-degrees/c...   \n",
       "\n",
       "                                          courseName  \\\n",
       "0           3D Design for Virtual Environments - MSc   \n",
       "1  Accounting, Accountability & Financial Managem...   \n",
       "2                       Accounting and Finance - MSc   \n",
       "3  Accounting, Financial Management and Digital B...   \n",
       "4                                     Addictions MSc   \n",
       "\n",
       "                  universityName  \\\n",
       "0  Glasgow Caledonian University   \n",
       "1          King’s College London   \n",
       "2            University of Leeds   \n",
       "3          University of Reading   \n",
       "4          King’s College London   \n",
       "\n",
       "                                         facultyName isItFullTime  \\\n",
       "0        School of Engineering and Built Environment    Full time   \n",
       "1                             King’s Business School    Full time   \n",
       "2                   Leeds University Business School    Full time   \n",
       "3                             Henley Business School    Full time   \n",
       "4  Institute of Psychiatry, Psychology and Neuros...    Full time   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  3D visualisation and animation play a role in ...  September   \n",
       "1  Our Accounting, Accountability & Financial Man...  September   \n",
       "2  Businesses and governments rely on sound finan...  September   \n",
       "3  Embark on a professional accounting career wit...  September   \n",
       "4  Join us for an online session for prospective ...  September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  \\n          \\n\\n\\n\\n             Please see th...      MSc   \n",
       "1  \\n          \\n\\n\\n\\n             Please see th...      MSc   \n",
       "2  \\n          \\n\\n\\n            UK: £18,000 (Tot...      MSc   \n",
       "3  \\n          \\n\\n\\n\\n             Please see th...      MSc   \n",
       "4  \\n          \\n\\n\\n\\n             Please see th...      MSc   \n",
       "\n",
       "           duration     city         country administration  \\\n",
       "0  1 year full-time  Glasgow  United Kingdom      On Campus   \n",
       "1         1 year FT   London  United Kingdom      On Campus   \n",
       "2  1 year full time    Leeds  United Kingdom      On Campus   \n",
       "3  1 year full time  Reading  United Kingdom      On Campus   \n",
       "4       One year FT   London  United Kingdom      On Campus   \n",
       "\n",
       "                            preprocessed_description  \n",
       "0  [3d, visualis, anim, play, role, mani, area, p...  \n",
       "1  [our, account, account, financi, manag, msc, c...  \n",
       "2  [busi, govern, reli, sound, financi, knowledg,...  \n",
       "3  [embark, profession, account, career, academ, ...  \n",
       "4  [join, us, onlin, session, prospect, student, ...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
